% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/plot_feature_importance_explainer.R
\name{plot.feature_importance_explainer}
\alias{plot.feature_importance_explainer}
\title{Plots Variable Importance}
\usage{
\method{plot}{feature_importance_explainer}(x, ..., max_vars = NULL,
  bar_width = 10)
}
\arguments{
\item{x}{a variable dropout exlainer produced with the 'feature_importance' function}

\item{...}{other explainers that shall be plotted together}

\item{max_vars}{maximum number of variables that shall be presented for for each model. By default NULL what means all variables}

\item{bar_width}{width of bars. By default 10}
}
\value{
a ggplot2 object
}
\description{
Function \code{plot.feature_importance_explainer} plots variable importance calculated as
changes in the loss function after variable drops.
It uses output from \code{feature_importance} function that corresponds to permutation based measure of variable importance.
Variables are sorted in the same order in all panels.
The order depends on the average drop out loss.
In different panels variable contributions may not look like sorted if variable importance is different in different in different mdoels.
Find more detailes in the \href{https://pbiecek.github.io/PM_VEE/variableImportance.html}{Feature Importance Chapter}.
}
\examples{

 \dontrun{
library("DALEX")
library("randomForest")

 titanic <- na.omit(titanic)
 model_titanic_rf <- randomForest(survived == "yes" ~ gender + age + class + embarked +
                                    fare + sibsp + parch,  data = titanic)
 explain_titanic_rf <- explain(model_titanic_rf,
                           data = titanic[,-9],
                           y = titanic$survived == "yes")

vd_rf <- feature_importance(explain_titanic_rf)
plot(vd_rf)

HR_rf_model <- randomForest(status~., data = HR, ntree = 100)
explainer_rf  <- explain(HR_rf_model, data = HR, y = HR$status)
vd_rf <- feature_importance(explainer_rf, type = "raw",
                            loss_function = loss_cross_entropy)
head(vd_rf)
plot(vd_rf)

HR_glm_model <- glm(status == "fired"~., data = HR, family = "binomial")
explainer_glm <- explain(HR_glm_model, data = HR, y = HR$status == "fired")
vd_glm <- feature_importance(explainer_glm, type = "raw",
                        loss_function = loss_root_mean_square)
head(vd_glm)
plot(vd_glm)

library("xgboost")
model_martix_train <- model.matrix(status == "fired" ~ . -1, HR)
data_train <- xgb.DMatrix(model_martix_train, label = HR$status == "fired")
param <- list(max_depth = 2, eta = 1, silent = 1, nthread = 2,
              objective = "binary:logistic", eval_metric = "auc")
HR_xgb_model <- xgb.train(param, data_train, nrounds = 50)
explainer_xgb <- explain(HR_xgb_model, data = model_martix_train,
                     y = HR$status == "fired", label = "xgboost")
vd_xgb <- feature_importance(explainer_xgb, type = "raw")
head(vd_xgb)

plot(vd_glm, vd_xgb, bar_width = 5)
 }

}
\references{
Predictive Models: Visualisal Exploration, Explanation and Debugging \url{https://pbiecek.github.io/PM_VEE}
}
